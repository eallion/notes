# 我看见的世界--李飞飞自传

## 第六章 北极星

他们需要已经分类的图片来训练算法，让计算机可以自动识别新加入的图片。

> 策划100个类别的图片，让每个类别都包含各种各样的例子，这比我这辈子做过的任何事情都要费力。
>
> 我和彼得罗的目标是建立一个包含100个图像类别的数据集，但我们一直在苦苦思索如何决定应该包括哪些类别。我们担心如果由我们自己来选择，结果可能会带有偏见——甚至在潜意识里，我们会倾向于选择我们知道算法更有可能成功识别的图像类别。
>
> 词典对某些词的解释有一种优雅的意味。大部分词是名词，强调的是有形的、看得见的东西——换句话说，就是物体，或者像小猎犬那样的动物。这些看上去正是我们想要的类别。而且每个字母开头的名词数量基本是均匀的，我觉得分布得很公正。于是我想：让词典来替我们做选择，如何？
>
> 我们花了几个月的时间手动查询图像搜索引擎，挑选出最好的结果，然后裁剪和调整照片的尺寸，确保一致性。
> 
> 我们的图像集于2004年完工，成为有史以来为机器学习配置的最大规模的图像集合，里面有超过9000个图像，分布在100个类别中。这是前所未有的，我迫不及待地想看看这个图像集能解锁什么奥秘。
> 
> 另外，我还忍不住实现了一个细节：我独自完成了一个新类别的图像整理，虽然耗时耗力，但我想用这种开玩笑的方式“嘲笑”导师。如果彼得罗想要100个类别，我就给他101个。
> 
> 新数据集的官方名称叫“Caltech 101”（加州理工学院101类图像数据集），这套训练图像集内容极其丰富多样。
> 
> 我们的优势是数据量，可就连数据量的问题也显得扑朔迷离。我不得不承认，其实101这个数字并没什么特别之处，它不是经过证实的结果，甚至不是从理论中推导出的原则性估计。这只是我和导师在摆得像霍克尼画作一样的午餐盘上玩“胆小鬼游戏”的结果。
> 
> 我再次回到文献中，这次是怀着复仇的心情。如果不是101个类别，那应该是多少个？200个？500个？还是1000个？我想，拜托，千万别是1000个。我下定决心，无论如何都要在茫茫文献中找到一丝线索。
> 
>我费了一番功夫，终于找到了一些资料。这些资料甚至来自一个熟悉的来源——现代视觉研究成果的主要贡献者之一欧文·比德曼。他的这篇论文发表于1983年。他讨论了如何利用基本几何形状的知识来识别复杂的物体。在论述和推导结论的过程中，比德曼试图回答一个看似简单的问题：世界上大约有多少独特的“事物”类别？也就是说，如果把所有的事物都相加——包括“摇椅”“企鹅”“跑车”“拉布拉多”“山”和其他所有东西——总数会是多少？
>
>比德曼采用了一种基于对英语语言的分析的独特方法，令我非常钦佩。单词在帮助我们对所见事物进行分类方面发挥着基础性的作用，因此他推断，对所有离散且可量化的事物的单词（即英文中的可数名词）进行计数，将是一个很好的起点。然后，他又计算出每个可数名词有多少个真正不同的变体，就像“杯子”这样单一类别的物体可能包括带华丽把手的白色茶具、色彩鲜艳的咖啡杯和普通的透明玻璃杯。由于某些类别比其他类别更具多样性，他通过假设一个合理的平均值将问题简化为一个简单的乘法问题，从而计算出总数。
>
>这个数字是巨大的。无比的大。不是1000个，不是2000个，甚至不是5000个。当然，更不是我们花了几个月搜集的那101个类别。
>
>是3万个。
>
>我完全不知道要对这个数字作何感想。创建Caltech 101已经让我感觉像是一项无比艰巨的任务，而现在又多了两个数量级。

## 第七章 一个假设

WordNet 这个项目的灵感源于两个同样雄心勃勃的问题：如果我们能够将人类通过语言表达的每一个概念都组织到一个庞大的单词数据库中，会发生什么？如果这些单词不是像词典中那样按照字母顺序排列，而是根据它们之间的意义联系进行连接，会造成什么影响呢？例如，我们不因为拼写接近而把“apple”（苹果）这个词与“appliance”（器具）进行关联，而是将它与“food”（食物）、“fruit”（水果）、“tree”（树）等一系列相关的词汇进行集群配对。这样形成的词汇数据库就像一张地图，将人类所珍视的一切（也就是我们用词汇描述的一切）排列在一个相连的空间里。简而言之，这就是WordNet。

1985年启动以来，WordNet已经发展到极其庞大的规模，收录了超过14万个英文单词，并迅速扩展到新的语言。

为了帮助我加深理解，克里斯蒂安又提到了一个相关的项目，旨在用视觉示例（如照片或图表）来阐释WordNet包含的每一个概念。虽然这个计划后来被搁置了，但我对它很感兴趣。

也许存在这样的可能性：让算法能够识别出任何东西的秘诀，就在于打造一个无所不包的数据训练集。

有上万个类别的数据集有什么用？大部分模型连一两个类别都识别不准！

你知道用这么多图像训练一个模型要花多长时间吗？飞飞，这个时间可是用“年”来计算的。

别人要怎么下载呢？你这个图像总量比大多数硬盘的存储量还要大。

具体怎么做，你有计划了吗？几百万张图谁来做标注？要花多长时间？怎么验证所有内容的准确性呢？

在2006年，算法是计算机视觉的中心，而数据这个话题并不十分吸引人。只需要推出一个闪亮的新算法，装饰以华丽的数学公式，就可以立刻引发关注。而数据生活在算法的阴影之下，仅仅被视为训练工具，就像成长中的孩子玩的玩具一样。

我们以WordNet为起点，开始进行删减。虽然WordNet的卖点是规模巨大、细节丰富，但我们知道，其中的大部分内容对我们来说并不必要。ImageNet的目的是捕捉事物的世界，而不涉及动作或描述，因此我们明确了第一批要删除的内容：所有的动词和形容词。但就算只剩下名词，处理起来也很复杂。像“真相”或“意识”这样的抽象概念是没有办法用影像记录的，只有指代实体对象的名词才会被纳入数据库。一般来说，我们需要的是有形、可数的物体。其他词汇都被删除了。

总的来说，WordNet中的14万个条目大部分都被我们删除了，只剩下可以用图像表示且可以计数的一小部分，约有2.2万个，虽然这个数量仍比我听说过的任何机器学习训练图像集都要大很多倍，但与初始的词汇量相比，已经大幅减少，而且跟比德曼估算的3万个种类非常接近。

于是我们确定了一个目标，为每个物品类别搜集1000张不同的照片：1000张不同的小提琴照片、1000张不同的德国牧羊犬照片、1000张不同的抱枕照片，直到涵盖全部2.2万个类别，也就是一共需要大约2000万张图片。但即便是这个数字，也只是最终成品数据库的情况。我们可能需要从数亿张照片，甚至10亿张照片中筛选，才能达到目标。

几个世纪后，新兴的众包实践基于同样的理念：真正的智能自动化仍然最适合由人类来完成。亚马逊土耳其机器人（Amazon Mechanical Turk，AMT）围绕这个概念建立了一个市场，“请求者”可以发布“人类智能任务”，由贡献者完成，这些贡献者被称为“土耳其人”（Turker），他们可能来自世界上的任何地方。从理论上讲，这个模式很合理，似乎可以提供我们想要的一切：既有人工标注图片带来的智慧成分，又有与自动化相当的速度与规模。有趣的是，亚马逊称之为“人工人工智能”，这个名字相当贴切。

亚马逊土耳其机器人改变了一切。它把我们起初的大学生标注员队伍变成了一个由数十人、数百人、数千人组成的国际团队。随着我们获得的支持不断扩大，邓嘉给出的预计完成时间急剧缩短，先是15年，然后是10年、5年、2年，最后不到1年。这为我们提供了全新的视角来看待预算，彻底颠覆了ImageNet的成本效益。曾几何时，我们的预算只能招到几个标注员，连一个房间都站不满，而现在足以聘请一支遍布全球并通过互联网连接的众包团队。

2009年6月，ImageNet的初始版本终于完成了，这在很大程度上得益于斯坦福大学提供的新研究资金。尽管我们一路上遇到了许多挑战，但我们最终成功达成了目标：收集了1500万张图片，涵盖了2.2万个不同类别。这些图片筛选自近10亿张候选图片，并由来自167个国家的4.8万多名全球贡献者进行了标注。ImageNet不仅在规模和多样性上达到了我们多年来梦寐以求的水平，还保持了一致的精确度：每张图片都经过了手工标注，并在层次结构中进行了组织，经过了三重验证。

从数量上看，我们已经实现了既定目标，建立起了当时人工智能史上最大的人工编辑数据集。但在这些数字之外，最让我感动的成就是我们所构建的真实世界本体。这个本体是人类从零开始策划的，既包含视觉图像，又能传达逻辑概念，其唯一的目的就是教导机器。



